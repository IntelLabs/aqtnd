{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169660fa",
   "metadata": {},
   "source": [
    "### Demo: Learning bond sizes for random 1D Heisenberg Hamiltonians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922c95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "fpath = \"./mps_heis_data.h5\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c626b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Matt's data\n",
    "f = h5py.File(fpath, 'r')\n",
    "\n",
    "cmt='''\n",
    "File mps_heis_data.h5 has one array of shape (10121, 50, 4)\n",
    "- index 1 runs over the 10121 random instances of heisenberg spin-1/2 H's. Each H is of the form\n",
    "H = \\sum_{j, j+1} J_j S_j \\dot S_{j+1} + \\sum_j h_j S^z_j\n",
    "\t- the couplings J_j are random gaussian variables with mean -1 (antiferromagnetic) and variance 0.1\n",
    "\t- the fields h_j are random gaussian variables with mean 0 and variance 0.1\n",
    "\t- the chain is of length L = 50\n",
    "- index 2 runs over the physical index {j} of the spin chain\n",
    "- index 3 labels the stored data as follows:\n",
    "\t- k == 0: vector of the J_j's. This is of size 49 (open boundary conditions) so there is a zero prepended\n",
    "\t\te.g. element (100, 29, 0) stores the value of J_{28} which is the coupling between the 28th and 29th qubit\n",
    "\t- k == 1: vector of the h_j's. This is of size 50\n",
    "\t- k == 2: vector of the *uncompressed* bond dimension of the ground state MPS |psi>\n",
    "\t- k == 3: vector of the *compressed* BD of an approximate ground state MPS |phi>\n",
    "\n",
    "The compressed approximation |phi> satisfies |<phi | psi>| > 1 - 1e-6.\n",
    "\n",
    "Notes on DMRG:\n",
    "\t- The DRMG algorithm that produced |psi> kept all singular values above 1e-12\n",
    "\t- Convergence was deemed achieved at an additive energy tolerance of 1e-4.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3138ad59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0882e+00, -3.7055e-01,  2.0000e+00,  2.0000e+00],\n",
      "         [-9.3708e-01, -2.2749e-01,  4.0000e+00,  4.0000e+00],\n",
      "         [-6.4150e-01, -5.5574e-01,  7.0000e+00,  4.0000e+00],\n",
      "         ...,\n",
      "         [-1.2262e+00,  2.9413e-01,  4.0000e+00,  4.0000e+00],\n",
      "         [-9.9365e-01, -5.6239e-02,  2.0000e+00,  2.0000e+00],\n",
      "         [ 0.0000e+00,  1.2912e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-6.5802e-01, -1.3014e-01,  2.0000e+00,  2.0000e+00],\n",
      "         [-7.7733e-01,  2.3377e-02,  4.0000e+00,  4.0000e+00],\n",
      "         [-9.8828e-01, -4.4454e-01,  8.0000e+00,  7.0000e+00],\n",
      "         ...,\n",
      "         [-1.2862e+00,  1.6307e-01,  4.0000e+00,  4.0000e+00],\n",
      "         [-1.0901e+00,  6.4691e-01,  2.0000e+00,  2.0000e+00],\n",
      "         [ 0.0000e+00, -1.3289e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.3416e+00,  2.8993e-02,  2.0000e+00,  2.0000e+00],\n",
      "         [-8.7763e-01, -6.1247e-01,  4.0000e+00,  4.0000e+00],\n",
      "         [-1.2726e+00,  6.8783e-02,  8.0000e+00,  8.0000e+00],\n",
      "         ...,\n",
      "         [-6.2773e-01, -4.0959e-01,  4.0000e+00,  4.0000e+00],\n",
      "         [-6.8965e-01,  8.3406e-02,  2.0000e+00,  2.0000e+00],\n",
      "         [ 0.0000e+00, -5.5444e-02,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.5849e-01,  6.8388e-01,  2.0000e+00,  2.0000e+00],\n",
      "         [-1.2058e+00,  5.3880e-03,  4.0000e+00,  4.0000e+00],\n",
      "         [-6.1193e-01, -3.8180e-01,  7.0000e+00,  7.0000e+00],\n",
      "         ...,\n",
      "         [-9.3473e-01,  2.9562e-01,  4.0000e+00,  4.0000e+00],\n",
      "         [-6.9268e-01,  2.4695e-01,  2.0000e+00,  2.0000e+00],\n",
      "         [ 0.0000e+00, -1.2753e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-8.3374e-01,  2.1945e-01,  2.0000e+00,  2.0000e+00],\n",
      "         [-8.4830e-01, -1.1529e-01,  4.0000e+00,  2.0000e+00],\n",
      "         [-5.8277e-01,  1.2191e-01,  7.0000e+00,  3.0000e+00],\n",
      "         ...,\n",
      "         [-5.6843e-01,  1.0017e-01,  4.0000e+00,  4.0000e+00],\n",
      "         [-1.1865e+00,  9.1052e-01,  2.0000e+00,  2.0000e+00],\n",
      "         [ 0.0000e+00, -3.1383e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-8.7316e-01,  2.9701e-01,  2.0000e+00,  2.0000e+00],\n",
      "         [-1.9348e+00, -2.5883e-01,  4.0000e+00,  4.0000e+00],\n",
      "         [-1.1146e+00, -3.0301e-01,  8.0000e+00,  6.0000e+00],\n",
      "         ...,\n",
      "         [-1.3761e+00, -1.1030e-01,  4.0000e+00,  3.0000e+00],\n",
      "         [-1.8459e+00,  2.9069e-02,  2.0000e+00,  2.0000e+00],\n",
      "         [ 0.0000e+00, -2.5383e-01,  0.0000e+00,  0.0000e+00]]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(f['heis-bd-data'][:,:,:])\n",
    "# np.array(data)\n",
    "print(data)\n",
    "Nsites = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4c18a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10121, 50, 4])\n",
      "max dmrg bond: 226.0\n",
      "max overlap bond: 97.0\n"
     ]
    }
   ],
   "source": [
    "# Get max bonds, for coarse-graining later\n",
    "print( data.shape )\n",
    "data[0,:,2]\n",
    "\n",
    "max_dmrg_bond = torch.max(data[:,:,2])\n",
    "print(f'max dmrg bond: {max_dmrg_bond}')\n",
    "\n",
    "max_overlap_bond = torch.max(data[:,:,3])\n",
    "print(f'max overlap bond: {max_overlap_bond}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0655ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cefc71af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8602\n",
      "torch.Size([8602, 50, 4])\n",
      "torch.Size([1519, 50, 4])\n"
     ]
    }
   ],
   "source": [
    "# Coarse-grain the data\n",
    "\n",
    "nslots = 30.\n",
    "\n",
    "def coarsegrain_dmrg_bonddims(inp):\n",
    "    return torch.round( (nslots/max_dmrg_bond)*inp )#.type(torch.int)\n",
    "\n",
    "def uncoarsegrain_dmrg_bonddims(inp):\n",
    "    return torch.round( (max_dmrg_bond/nslots)*inp )#.type(torch.int)\n",
    "\n",
    "def coarsegrain_overlap_bonddims(inp):\n",
    "    return torch.round( (nslots/max_overlap_bond)*inp )#.type(torch.int)\n",
    "\n",
    "def uncoarsegrain_overlap_bonddims(inp):\n",
    "    return torch.round( (max_overlap_bond/nslots)*inp )#.type(torch.int)\n",
    "\n",
    "'''\n",
    "# Quick tests:\n",
    "print( coarsegrain_dmrg_bonddims(np.array([10,20,30])) )\n",
    "print( uncoarsegrain_dmrg_bonddims(np.array([10,20,30])) )\n",
    "print( coarsegrain_overlap_bonddims(np.array([10,20,30])) )\n",
    "print( uncoarsegrain_overlap_bonddims(np.array([10,20,30])) )\n",
    "'''\n",
    "\n",
    "# Coarse-graining implemented here\n",
    "coarsegr_data = data.type(torch.float32)\n",
    "coarsegr_data[:,:,2] = coarsegrain_dmrg_bonddims(data[:,:,2])\n",
    "coarsegr_data[:,:,3] = coarsegrain_overlap_bonddims(data[:,:,2])\n",
    "\n",
    "\n",
    "# Split into training and testing data (do 85%-15%)\n",
    "frac_train = 0.85\n",
    "size_train = int(frac_train*coarsegr_data.shape[0])\n",
    "print(size_train)\n",
    "training_data = coarsegr_data[:size_train,:,:]\n",
    "testing_data  = coarsegr_data[size_train:,:,:]\n",
    "\n",
    "print(training_data.shape)\n",
    "print(testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58ea0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13cd6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class CustomImageDataset(Dataset):\n",
    "#     def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "#         self.img_labels = pd.read_csv(annotations_file)\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_labels)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "#         image = read_image(img_path)\n",
    "#         label = self.img_labels.iloc[idx, 1]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "#         return image, label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "730b5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to define DataSet class\n",
    "# Must *use* a DataLoader, but don't need new class\n",
    "\n",
    "class HeisDMRGbondsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,inp_data, transform=None, target_transform=None):\n",
    "        self.raw_data = inp_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.raw_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        did = 20\n",
    "        \n",
    "        hamdata = self.raw_data[idx, :, 0:2]\n",
    "#         hamdata = torch.expand_dims(self.raw_data[idx, :, 0:2],axis=0)\n",
    "#         hamdata = torch.array([self.raw_data[idx, :, 0:2]])\n",
    "\n",
    "        dvals   = self.raw_data[idx, :, 2] #[idx, :, 2:3]\n",
    "#         dval   = self.raw_data[idx, did, 2] #[idx, :, 2:3]\n",
    "        \n",
    "        return hamdata, dvals#.astype(int)\n",
    "#         return hamdata, int(dval)\n",
    "        \n",
    "        \n",
    "# class HeisOverlapBondsDataset(Dataset):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "649c7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'reg' means 'regular bonds'\n",
    "# Note 'as type' to go to 32-bit float\n",
    "reg_training_data = HeisDMRGbondsDataset(training_data)\n",
    "reg_testing_data  = HeisDMRGbondsDataset(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1622653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-1.0882, -0.3706],\n",
      "        [-0.9371, -0.2275],\n",
      "        [-0.6415, -0.5557],\n",
      "        [-0.6356,  0.0032],\n",
      "        [-1.2323,  0.1899],\n",
      "        [-1.1554,  0.2513],\n",
      "        [-0.9041, -0.4830],\n",
      "        [-0.8500,  0.7034],\n",
      "        [-1.2217,  0.4572],\n",
      "        [-0.7484, -0.6532],\n",
      "        [-1.1959,  0.0681],\n",
      "        [-1.2091,  0.1533],\n",
      "        [-0.9521,  0.1105],\n",
      "        [-1.7078,  0.3483],\n",
      "        [-0.4551, -0.0738],\n",
      "        [-1.3972,  0.0123],\n",
      "        [-1.1474,  0.0273],\n",
      "        [-0.8863, -0.7602],\n",
      "        [-1.2586, -0.8437],\n",
      "        [-1.5607,  0.2770],\n",
      "        [-1.4163, -0.2554],\n",
      "        [-1.2745, -0.0767],\n",
      "        [-0.9692, -0.1978],\n",
      "        [-0.8101, -0.0828],\n",
      "        [-0.6671,  0.1417],\n",
      "        [-0.8453, -0.3644],\n",
      "        [-0.9117,  0.4260],\n",
      "        [-0.9629, -0.2203],\n",
      "        [-0.8452, -0.2369],\n",
      "        [-0.8597, -0.1995],\n",
      "        [-0.9924, -0.5638],\n",
      "        [-0.9245, -0.0166],\n",
      "        [-0.6561,  0.0212],\n",
      "        [-1.1099, -0.0297],\n",
      "        [-0.6324,  0.4260],\n",
      "        [-1.5027,  0.0338],\n",
      "        [-1.0957,  0.3428],\n",
      "        [-0.8974,  0.0286],\n",
      "        [-1.1568,  0.7176],\n",
      "        [-0.6915, -0.2179],\n",
      "        [-1.2689, -0.0799],\n",
      "        [-1.0303, -0.2003],\n",
      "        [-0.8472, -0.0770],\n",
      "        [-0.9597, -0.2180],\n",
      "        [-1.0150,  0.1785],\n",
      "        [-1.1648,  0.2825],\n",
      "        [-0.7892, -0.5650],\n",
      "        [-1.2262,  0.2941],\n",
      "        [-0.9936, -0.0562],\n",
      "        [ 0.0000,  0.1291]]), tensor([ 0.,  1.,  1.,  1.,  2.,  3.,  4.,  5.,  7.,  6.,  7.,  8.,  8.,  8.,\n",
      "         7.,  7.,  6.,  5.,  5.,  5.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  5.,\n",
      "         6.,  7.,  8., 10., 11., 13., 14., 16., 17., 17., 17., 16., 15., 12.,\n",
      "         8.,  6.,  4.,  2.,  1.,  1.,  0.,  0.]))\n",
      "(tensor([[-1.4533, -0.2471],\n",
      "        [-1.0992, -0.0204],\n",
      "        [-0.6801,  0.2825],\n",
      "        [-0.7859, -0.2717],\n",
      "        [-0.9044,  0.3347],\n",
      "        [-1.3883,  0.2464],\n",
      "        [-1.1447, -0.0932],\n",
      "        [-0.7643, -0.3033],\n",
      "        [-0.7949, -0.0562],\n",
      "        [-1.3965, -0.2835],\n",
      "        [-1.0218, -0.6170],\n",
      "        [-0.6107,  0.2240],\n",
      "        [-1.4367, -0.2477],\n",
      "        [-1.3151, -0.1462],\n",
      "        [-0.9252, -0.4857],\n",
      "        [-0.8789,  0.3695],\n",
      "        [-1.2097, -0.4411],\n",
      "        [-0.8846, -0.1444],\n",
      "        [-1.0124,  0.6098],\n",
      "        [-0.8903,  0.1984],\n",
      "        [-1.6196,  0.1120],\n",
      "        [-0.6615, -0.4670],\n",
      "        [-1.0547, -0.3367],\n",
      "        [-1.4175,  0.5967],\n",
      "        [-0.9011,  0.6436],\n",
      "        [-1.0555,  0.2613],\n",
      "        [-1.1698, -0.2353],\n",
      "        [-0.5738, -0.0291],\n",
      "        [-1.1489, -0.5138],\n",
      "        [-1.0443,  0.4670],\n",
      "        [-0.1769, -0.3447],\n",
      "        [-0.8356,  0.3040],\n",
      "        [-1.1709, -0.0870],\n",
      "        [-1.0712,  0.0177],\n",
      "        [-0.5857, -0.0694],\n",
      "        [-0.7128, -0.0619],\n",
      "        [-1.2563,  0.3191],\n",
      "        [-0.7918, -0.2838],\n",
      "        [-0.6459,  0.0598],\n",
      "        [-1.3360, -0.2555],\n",
      "        [-0.9122, -0.1520],\n",
      "        [-1.2748, -0.5383],\n",
      "        [-1.1727, -0.3033],\n",
      "        [-0.9381,  0.1013],\n",
      "        [-0.9679, -0.0523],\n",
      "        [-0.9556,  0.7945],\n",
      "        [-0.8047, -0.2745],\n",
      "        [-0.8902,  0.3437],\n",
      "        [-1.1258, -0.1294],\n",
      "        [ 0.0000, -0.5067]]), tensor([ 0.,  1.,  1.,  2.,  3.,  5.,  6.,  7.,  8.,  8.,  7.,  6.,  7.,  7.,\n",
      "         6.,  6.,  7.,  6.,  7.,  7.,  7.,  7.,  8.,  8.,  8.,  9.,  9.,  8.,\n",
      "         8.,  8.,  8.,  9., 10., 10., 10., 10., 10., 10.,  9.,  9.,  9.,  8.,\n",
      "         6.,  4.,  3.,  2.,  1.,  1.,  0.,  0.]))\n"
     ]
    }
   ],
   "source": [
    "# Make sure output looks correct\n",
    "print( reg_training_data[0] )\n",
    "print( reg_testing_data[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57ff053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([64, 50, 2]) torch.float32\n",
      "Shape of y: torch.Size([64, 50]) torch.float32\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "reg_train_dataloader = DataLoader(reg_training_data,batch_size=batch_size)\n",
    "reg_test_dataloader = DataLoader(reg_testing_data,batch_size=batch_size)\n",
    "\n",
    "for X, y in reg_test_dataloader:\n",
    "    print(f\"Shape of X: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "\n",
    "print(nslots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86d920e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try *not* doing nslots for now... try to learn d values directly...\n",
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=50, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "print(\"try *not* doing nslots for now... try to learn d values directly...\")\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(Nsites*2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(512, int(nslots) )\n",
    "            nn.Linear(512, Nsites )\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(f\"x: {x}\")\n",
    "        x = self.flatten(x)\n",
    "#         x = nn.Flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca167fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_pred,y_val):\n",
    "    return torch.sum(torch.absolute(y_pred - y_val))\n",
    "loss_fn = custom_loss\n",
    "\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss() # <-- not appropriate for us\n",
    "# loss_fn = nn.L1Loss\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # lr = learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # lr = learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87ccf12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "#             print('pred: ',X)\n",
    "#             print('y: ',y)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c71523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aeea7155",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 16190.856445  [    0/ 8602]\n",
      "loss: 7045.499512  [ 1280/ 8602]\n",
      "loss: 6800.855469  [ 2560/ 8602]\n",
      "loss: 5757.700195  [ 3840/ 8602]\n",
      "loss: 6297.056152  [ 5120/ 8602]\n",
      "loss: 6406.628418  [ 6400/ 8602]\n",
      "loss: 6055.835938  [ 7680/ 8602]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 7093.830566  [    0/ 8602]\n",
      "loss: 6645.979492  [ 1280/ 8602]\n",
      "loss: 6623.170898  [ 2560/ 8602]\n",
      "loss: 5618.173828  [ 3840/ 8602]\n",
      "loss: 6205.225586  [ 5120/ 8602]\n",
      "loss: 6314.202148  [ 6400/ 8602]\n",
      "loss: 6004.837891  [ 7680/ 8602]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 7043.664062  [    0/ 8602]\n",
      "loss: 6675.809570  [ 1280/ 8602]\n",
      "loss: 6637.380859  [ 2560/ 8602]\n",
      "loss: 5620.492676  [ 3840/ 8602]\n",
      "loss: 6246.716797  [ 5120/ 8602]\n",
      "loss: 6367.268555  [ 6400/ 8602]\n",
      "loss: 6017.033203  [ 7680/ 8602]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 7091.979980  [    0/ 8602]\n",
      "loss: 6654.039551  [ 1280/ 8602]\n",
      "loss: 6593.653809  [ 2560/ 8602]\n",
      "loss: 5621.009766  [ 3840/ 8602]\n",
      "loss: 6193.525879  [ 5120/ 8602]\n",
      "loss: 6355.336914  [ 6400/ 8602]\n",
      "loss: 5994.634766  [ 7680/ 8602]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 7055.705566  [    0/ 8602]\n",
      "loss: 6595.994141  [ 1280/ 8602]\n",
      "loss: 6593.440430  [ 2560/ 8602]\n",
      "loss: 5625.597656  [ 3840/ 8602]\n",
      "loss: 6228.818848  [ 5120/ 8602]\n",
      "loss: 6308.419922  [ 6400/ 8602]\n",
      "loss: 6016.386719  [ 7680/ 8602]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(reg_train_dataloader, model, loss_fn, optimizer)\n",
    "#     test(reg_test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05cca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pth\")\n",
    "# print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b537023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork()\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57e69ba5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(y) # true value\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     pred = model(x)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pred) \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     predicted, actual = pred[0].argmax(0), y # It's like one-hot. Position with *highest* value gives answer\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pando/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [42], line 26\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#         print(f\"x: {x}\")\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#         x = nn.Flatten(x)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_relu_stack(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/pando/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pando/lib/python3.10/site-packages/torch/nn/modules/flatten.py:45\u001b[0m, in \u001b[0;36mFlatten.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x, y = reg_testing_data[0][0], reg_testing_data[0][1] \n",
    "# print(x)\n",
    "# print(y) # true value\n",
    "with torch.no_grad():\n",
    "#     pred = model(x)\n",
    "    pred = model(torch.flatten(x))\n",
    "    print(pred) \n",
    "#     predicted, actual = pred[0].argmax(0), y # It's like one-hot. Position with *highest* value gives answer\n",
    "    predicted, actual = pred[0], y\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724616a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd15813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9af739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fa4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd90a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8823aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
